{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución Prueba Técnica, Jully Paola Peña Pacheco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Preliminar de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente se importan algunas librerias comunmente útiles para el tratamiento de datos. No todas las librerias usadas a lo largo del código  son importadas aqui; en general, cada libreria es agregada conforme la necesidad y no con una evaluación a priori de su utilidad dentro de la tarea a desarrollar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer paso, fue hecho un examen general de la información contenida en el archivo Train.csv. De este examen se concluyó que el conjunto de datos presenta un formato bastante irregular, con signos de puntuación dispersos en partes diferentes de cada línea. Eso es importante porque signos como la coma, el punto y coma, o las comillas pueden generar errores a la hora de separar la información de cada columna; de hecho en el primer intento de importar los datos de Training con pandas (read_csv es una forma muy práctica para obtener los datos en un dataframe, lo que facilita su posterior análisis) se obtiene el error: \"Error tokenizing data. C error: Expected 3 fields in line 37569, saw 5\", al examinar la línea referida, resulta que las comas dentro de la descripción están fuera de las comillas que le indicarian que todo hace parte del mismo \"string\". Como no se sabe si otras lineas presentan el mismo problema, en este o en cualquier otro conjunto de datos con los que se vaya a trabajar en esta tarea, se resolvió automatizar la separación de los 3 items presentes en cada fila en una forma que resulte funcional también para otros conjuntos de datos. Sin embargo, es claro que para esto debe asumirse que los datos no vienen en un formato totalmente desordenado, sino que conservan ciertas caraterísticas comunes; en este caso, la característica común es que la primera y última comas son las que separan el texto 'title' de 'label' y de 'is_validated_by_human', respectivamente. Esta separación, y la definición de un dataframe con todos los datos es implementada en la celda a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38705 38705 38705\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>Human_validated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TELEPHONES</td>\n",
       "      <td>Teléfono Inalambrico Duo Motorola M700-2 + Han...</td>\n",
       "      <td>YES;;;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOTEBOOKS</td>\n",
       "      <td>Acer Aspire 7520 Notebook 17  Disco Ssd + Hdd ...</td>\n",
       "      <td>YES;;;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"TABLETS</td>\n",
       "      <td>\"\"Tablet Pc Box 7   Quad  1gb 8gb  Doble Cam  ...</td>\n",
       "      <td>YES\";;;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOTEBOOKS</td>\n",
       "      <td>Notebook Hp X360 15.6 Intel I5 1tb 8gb Win10 T...</td>\n",
       "      <td>YES;;;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOTEBOOKS</td>\n",
       "      <td>Notebook Hp 240 G5 Freedos Core I3 Dvd Hdmi 4g...</td>\n",
       "      <td>YES;;;\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label                                               Text  \\\n",
       "0  TELEPHONES  Teléfono Inalambrico Duo Motorola M700-2 + Han...   \n",
       "1   NOTEBOOKS  Acer Aspire 7520 Notebook 17  Disco Ssd + Hdd ...   \n",
       "2    \"TABLETS  \"\"Tablet Pc Box 7   Quad  1gb 8gb  Doble Cam  ...   \n",
       "3   NOTEBOOKS  Notebook Hp X360 15.6 Intel I5 1tb 8gb Win10 T...   \n",
       "4   NOTEBOOKS  Notebook Hp 240 G5 Freedos Core I3 Dvd Hdmi 4g...   \n",
       "\n",
       "  Human_validated  \n",
       "0        YES;;;\\n  \n",
       "1        YES;;;\\n  \n",
       "2       YES\";;;\\n  \n",
       "3        YES;;;\\n  \n",
       "4        YES;;;\\n  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set = open('Train.csv','r').readlines()\n",
    "Val_set = open('Validation.csv','r').readlines()\n",
    "\n",
    "def separate_cols(file):\n",
    "    labels=[]\n",
    "    texts=[]\n",
    "    human_validation=[]\n",
    "    \n",
    "    for i in file:\n",
    "        i = i.split(',')\n",
    "        labels.append(i[0])\n",
    "        texts.append(' '.join(i[1:-1]))\n",
    "        human_validation.append(i[-1])\n",
    "    \n",
    "    df = pd.DataFrame(list(zip(labels[1::], texts[1::], human_validation[1::])),\n",
    "               columns =['Label', 'Text', 'Human_validated'])\n",
    "           \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def_train_set = separate_cols(Train_set)\n",
    "#print(def_train_set.dtypes)\n",
    "\n",
    "print(np.size(def_train_set['Label']), np.size(def_train_set['Text']), np.size(def_train_set['Human_validated']))\n",
    "def_train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que los datos están separados en las tres columnas deseadas, leyenda, textos, y validación humana, se hace una verificación de las categorías identificadas en el conjunto de datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TELEPHONES', 'NOTEBOOKS', '\"TABLETS', 'TABLETS', 'CELLPHONES',\n",
       "       '\"NOTEBOOKS', '\"CELLPHONES', '\"TELEPHONES'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_train_set['Label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El hecho que el nombre de algunas categorias contenga caracteres adicionales hace que estas sean tomadas como categorias diferentes. Para corregir esto, se utilizan  \"regular expressions\" que remueven todo caracter no alfa-numérico. El proceso de romoción de caracteres no alpha-numericos se hará también para la última columna del dataframe principal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38705\n",
      "38705\n",
      "['TELEPHONES' 'NOTEBOOKS' 'TABLETS' 'CELLPHONES']\n",
      "['YES' 'NO']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>Human_validated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TELEPHONES</td>\n",
       "      <td>Teléfono Inalambrico Duo Motorola M700-2 + Han...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOTEBOOKS</td>\n",
       "      <td>Acer Aspire 7520 Notebook 17  Disco Ssd + Hdd ...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TABLETS</td>\n",
       "      <td>\"\"Tablet Pc Box 7   Quad  1gb 8gb  Doble Cam  ...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOTEBOOKS</td>\n",
       "      <td>Notebook Hp X360 15.6 Intel I5 1tb 8gb Win10 T...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOTEBOOKS</td>\n",
       "      <td>Notebook Hp 240 G5 Freedos Core I3 Dvd Hdmi 4g...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label                                               Text  \\\n",
       "0  TELEPHONES  Teléfono Inalambrico Duo Motorola M700-2 + Han...   \n",
       "1   NOTEBOOKS  Acer Aspire 7520 Notebook 17  Disco Ssd + Hdd ...   \n",
       "2     TABLETS  \"\"Tablet Pc Box 7   Quad  1gb 8gb  Doble Cam  ...   \n",
       "3   NOTEBOOKS  Notebook Hp X360 15.6 Intel I5 1tb 8gb Win10 T...   \n",
       "4   NOTEBOOKS  Notebook Hp 240 G5 Freedos Core I3 Dvd Hdmi 4g...   \n",
       "\n",
       "  Human_validated  \n",
       "0             YES  \n",
       "1             YES  \n",
       "2             YES  \n",
       "3             YES  \n",
       "4             YES  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_non_alphan(column, separator):\n",
    "    def_column = []  \n",
    "    for label in column:\n",
    "        label = def_column.append(re.sub(r'\\W+', separator, label))\n",
    "    return def_column\n",
    "    \n",
    "#print (def_labels[0:10])\n",
    "def_labels = remove_non_alphan(def_train_set['Label'], separator = '')\n",
    "def_HV = remove_non_alphan(def_train_set['Human_validated'], separator = '')\n",
    "\n",
    "print(np.size(def_labels))\n",
    "print(np.size(def_HV))\n",
    "\n",
    "def_train_set['Label'] = def_labels\n",
    "def_train_set['Human_validated'] = def_HV\n",
    "\n",
    "print(def_train_set['Label'].unique())\n",
    "print(def_train_set['Human_validated'].unique())\n",
    "\n",
    "def_train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior, fue verificado que las categorias presentes son las correctas tanto en términos del tipo de producto, como en si este fue verificado por un humano o no. La columna central del dataframe irá requerir también de una limpieza de caracteres, palabras no significativas, y otros, pero esta no es necesária para este primer análisis sobre la distribución general de los datos. Así, el tratamiento completo de los textos en la columna 'Text', se hará más adelante, como preparación para la implementación del modelo predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de distribución de los datos\n",
    "\n",
    "Habiendo depurado el contenido de las columnas 'Labels' y 'Human_validated', es posible hacer un análisis sobre la presencia de 'skewed classes', lo cuál es un parámetro importante a tener en cuenta para la implementación de un algoritmo de clasificación. Para esto, se van a contar los elementos de cada clase presentes en el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TELEPHONES    14037\n",
      "CELLPHONES    12253\n",
      "NOTEBOOKS      6615\n",
      "TABLETS        5800\n",
      "Name: Label, dtype: int64\n",
      "NO     32893\n",
      "YES     5812\n",
      "Name: Human_validated, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(def_train_set['Label'].value_counts())\n",
    "print(def_train_set['Human_validated'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con relación a las cuatro categorías de clasificación, la cantidad de elementos marcados como 'TELEPHONES' es mas de dos veces la de los marcados como 'TABLETS', esto puede generar inconvenientes a la hora de entrenar un modelo, a menos que los datos de entrada contengan características unívocas como para que el agoritmo aprenda a identificar los elementos de una determinada categoria con confianza, aún con una cantidad menor de datos en esa categoría. En ese caso, 5800 datos puede ser una cantidad suficiente para que el algoritmo aprenda a diferenciar los elementos de la categoria 'TABLETS', pero este no es el único factor a considerar. \n",
    "\n",
    "Con relación a la cantidad de datos validados por humanos, estos están presentes en una cantidad que es al menos 6 veces menor que la de datos no validados por humanos. Normalmente podria asumirse que los datos validados son de mejor calidad, o sea que tenemos confianza en su clasificación. En ese caso, seria preferible entrenar el modelo apenas utilizando esos datos óptimizados, pues datos con clasificación errónea pueden aumentar el ruido y ser de hecho contraproducente tomarlos en cuenta. Aqui sin embargo, al no tener ninguna información de las métricas de evaluación del algoritmo que generó los datos, y teniendo en cuenta que el texto que describe un aparato electrónico puede contener características que pueden resultar confusas incluso para un humano cuando la clasificación es hecha apenas a partir de ese texto, no se considerará que los datos validados por humanos sean de mejor calidad, así que no se hará a priori ninguna selección de los datos a utilizar para el entrenamiento del modelo con base en este critério. \n",
    "\n",
    "Como no hay datos numéricos en ninguna de las columnas del dataframe, no se considera necesário una búsqueda de valores nulos, y por el tamaño de los subconjuntos de cada subcategoria, tampoco se considera necesário buscar si hay celdas vacias.\n",
    "\n",
    "Con esto, se hará un primer intento de entrenar un algoritmo utilizando todos los datos disponibles. Esto sólo es factible en un algoritmo que corra relativamente rápido y que sea simple de implementar. Para esto se usará un modelo de clasificación \"one vs. rest\" que utiliza un algoritmo de Suport Vector Machine con kernel lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words\n",
    "\n",
    "Los inputs del algoritmo se pasarán en el formato de un \"Bag of Words\" generado por CountVectorizer. Esta elección de debe a que, en este conjunto de datos específico, las palabras utilizadas en los títulos de los productos no se encajan dentro de un tipo de lenguaje en el que sea importante la identificación de un contexto semántico. Como hipótesis, se tiene que la asociación de palabras en este contexto podría de hecho empeorar el proceso de aprendizaje del algoritmo porque los productos de las diferentes categorías pueden tener muchas características comunes como marca, o tamanho de memória, que no tienen relación con el tipo de producto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de vectorizar los textos, serán removidos los caracteres no alphanuméricos con la intuición que esto pueda reducir el tiempo de computo de la vectorización y consecuentemente del entrenamiento del algoritmo, aunque no se espera que eso ayude a mejorar la clasificación porque de todas formas hay dentro de los textos muchos códigos que no son realmente palabras y en los cuales la remoción de esos caracteres no hace diferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 16725)\t1\n",
      "  (0, 9837)\t1\n",
      "  (0, 6968)\t1\n",
      "  (0, 12245)\t1\n",
      "  (0, 11440)\t1\n",
      "  (0, 9115)\t1\n",
      "  (0, 5110)\t1\n",
      "  (0, 9672)\t1\n"
     ]
    }
   ],
   "source": [
    "train_numpy = def_train_set['Text'].to_numpy()\n",
    "\n",
    "\n",
    "Train_text = remove_non_alphan(train_numpy, separator = ' ')\n",
    "#print(Train_text)\n",
    "train_x_vectors = vectorizer.fit_transform(Train_text)\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "print(type(train_x_vectors))\n",
    "print(train_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TELEPHONES' 'NOTEBOOKS' 'TABLETS' 'NOTEBOOKS' 'NOTEBOOKS' 'TABLETS'\n",
      " 'TABLETS' 'NOTEBOOKS' 'TABLETS' 'TABLETS']\n"
     ]
    }
   ],
   "source": [
    "y_train = def_train_set['Label'].to_numpy()\n",
    "print(y_train[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer intento de modelo predictivo con LinearSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos Suport Vector Machine son comunes para aprendizaje supervisado por su versatilidad en el trabajo con datos multidimensionales y su eficiente uso de memória. El modelo Linear Suport Vector Machine (LSVM) fue escogido en este caso sobre el modelo base SVM porque al ser un modelo de clasificación \"one vs all\" en vez de \"one vs. one\", este se entrena más rapidamente, lo que es una ventaja cuando el conjunto de datos es grande, o cuando se quiere hacer un test inicial, como es el caso aquí. Además, este soporta como entrada tanto matrices de tipo \"sparse\", como la dada por CounterVectorizer, como matrices \"densas\" como las dadas por Tokenizer. Así, en caso que sea identificado que una u otra técnica de vectorización del texto es más adecuada, el modelo puede ser adaptado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TELEPHONES'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "## FITTING\n",
    "\n",
    "clf_Lsvm = LinearSVC()\n",
    "Model1 = clf_Lsvm.fit(train_x_vectors, y_train)\n",
    "\n",
    "## PREDICTING IN AN EXAMPLE\n",
    "\n",
    "test_x = vectorizer.transform(['Motorola Moto G5 Plus Con Funda Y Vidrio De Regalo! Nuevos!'])\n",
    "Model1.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se deben evaluar las métricas del modelo. Para esto se preparan primero los datos del conjunto de validación, que seran los contenidos en el archivo Validation.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1245\n",
      "1245\n"
     ]
    }
   ],
   "source": [
    "## PREPARATION OF LABELS AND HUMAN VALIDATED COLUMNS\n",
    "\n",
    "def_val_set = separate_cols(Val_set)\n",
    "def_val_set.head()\n",
    "\n",
    "def_val_labels = remove_non_alphan(def_val_set['Label'], separator='')\n",
    "def_val_HV = remove_non_alphan(def_val_set['Human_validated'], separator='')\n",
    "\n",
    "print(np.size(def_val_labels))\n",
    "print(np.size(def_val_HV))\n",
    "def_val_set['Label'] = def_val_labels\n",
    "def_val_set['Human_validated'] = def_val_HV\n",
    "\n",
    "def_val_set.head()\n",
    "\n",
    "## PREPARATION OF THE TEXT USING COUNTVECTORIZER\n",
    "\n",
    "val_text_numpy = def_val_set['Text'].to_numpy()\n",
    "Val_text = remove_non_alphan(val_text_numpy, separator = ' ')\n",
    "val_x_vectors = vectorizer.transform(Val_text)\n",
    "\n",
    "\n",
    "val_label_numpy = def_val_set['Label'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evaluará la métrica F1 porque es esta es útil en conjuntos en que la cantidad de datos no es la misma para todas las categorias, y porque permite ver el rendimiento del modelo para cada una de las categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25433526 0.9888412  0.98224852 0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(val_label_numpy, Model1.predict(val_x_vectors), average=None, labels=['CELLPHONES', 'NOTEBOOKS', 'TABLETS', 'TELEPHONES']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El factor F1 indica que el modelo falla contundentemente al intentar predecir ejemplos de celulares y teléfonos. Posibles problemas en la distribución de los datos habian sido identificados antes, pero resulta curioso que  las peores métricas sean precisamente las de las dos categorias con más elementos. Eso indica que la calidad de los datos está comprometida, principalmente para las categorias 'CELLPHONES' y 'TELEPHONES'.\n",
    "\n",
    "Sin embargo, al evaluar también el conjunto de validación utilizado, sobre el cuál se calcula la métrica, se tiene que este, con sus 1245 elementos, representa apenas un 3% del total de los datos sumados en los conjuntos de entrenamiento y validación, cuando normalmente deberia ser de alrededor de 20%. \n",
    "\n",
    "Para identificar mejor la causa de los malos resultados en la métrica del modelo, se hará a continuación un análisis mas detallado de la distribución de los datos tanto en el conjunto de entrenamiento cuanto en el de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTEBOOKS     583\n",
      "TABLETS       512\n",
      "CELLPHONES    141\n",
      "TELEPHONES      9\n",
      "Name: Label, dtype: int64\n",
      "YES    1245\n",
      "Name: Human_validated, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(def_val_set['Label'].value_counts())\n",
    "print(def_val_set['Human_validated'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la distribución de los datos en este conjunto de validación, resulta claro que siempre será difícil obtener métricas estadísticamente significativas para las categorias 'CELLPHONES' y 'TELEPHONES' porque hay muy pocos elementos de esas categorías en ese conjunto. Esto es claramente visto en la matriz de confusión mostrada a continuación, en la que se ve que los 9 ejemplos de 'TELEPHONES' fueron predichos como siendo 'CELLPHONES'. Observese por ejemplo que en la categoria 'TABLETS' (linea 3) mas de 9 ejemplos fueron clasificados en la categoria equivocada, pero esto no afecta demasiado la métrica porque los 14 ejemplos mal clasificados representan apenas un 2.7 % del total, mientras que en el caso de la categoria 'CELLPONES', 9 ejemplos mal clasificados corresponden al 100 % de los datos.\n",
    "\n",
    "Otro item a resaltar, y que puede ser importante a la hora de evaluar si las metricas calculadas son realmente representativas del modelo, es el hecho que este conjunto de validación solamente contiene datos validados por usuários humanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22   0   0 119]\n",
      " [  0 576   4   3]\n",
      " [  1   6 498   7]\n",
      " [  9   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(val_label_numpy, Model1.predict(val_x_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis a posteriori de los datos\n",
    "\n",
    "Para tener una idea de como la clasificación de una categoria varia de acuerdo a su validación por usuário, y tener una idea de si ese parámetro representa o no una mejora en la calidad del input del conjunto de entrenamiento, puede ser interesante ver si la proporción de items validados por personas varia de una categoria para otra.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th>Human_validated</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CELLPHONES</th>\n",
       "      <th>NO</th>\n",
       "      <td>11594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YES</th>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">NOTEBOOKS</th>\n",
       "      <th>NO</th>\n",
       "      <td>3891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YES</th>\n",
       "      <td>2724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TABLETS</th>\n",
       "      <th>NO</th>\n",
       "      <td>3412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YES</th>\n",
       "      <td>2388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TELEPHONES</th>\n",
       "      <th>NO</th>\n",
       "      <td>13996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YES</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Text\n",
       "Label      Human_validated       \n",
       "CELLPHONES NO               11594\n",
       "           YES                659\n",
       "NOTEBOOKS  NO                3891\n",
       "           YES               2724\n",
       "TABLETS    NO                3412\n",
       "           YES               2388\n",
       "TELEPHONES NO               13996\n",
       "           YES                 41"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_train = def_train_set.groupby(['Label','Human_validated']).count()\n",
    "grouped_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CELLPHONES', 'NOTEBOOKS', 'TABLETS', 'TELEPHONES'])\n",
      "dict_keys(['CELLPHONES', 'NOTEBOOKS', 'TABLETS', 'TELEPHONES']) [659, 2724, 2388, 41] [11594, 3891, 3412, 13996]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "validated_dummy = pd.get_dummies(def_train_set['Human_validated'])\n",
    "#print(validated_dummy.head())\n",
    "\n",
    "\n",
    "def_train_set_dummy = pd.concat([def_train_set, validated_dummy], axis=1)\n",
    "def_train_set_dummy.head()\n",
    "\n",
    "symbols = def_train_set_dummy.groupby(['Label'])\n",
    "\n",
    "print(symbols.groups.keys())\n",
    "\n",
    "GROUPS = symbols.groups.keys()\n",
    "YES=[]\n",
    "NO=[]\n",
    "for i in symbols.groups:\n",
    "    a = symbols.get_group(i)\n",
    "    yes = a['YES'].sum()\n",
    "    no = a['NO'].sum()\n",
    "    YES.append(yes)\n",
    "    NO.append(no)\n",
    "\n",
    "   \n",
    "\n",
    "print(GROUPS, YES, NO)\n",
    "\n",
    "plt.bar(GROUPS, NO, width =0.8, label=\"Non validated by humans\")\n",
    "plt.bar(GROUPS, YES, width =0.5, label= 'Human validated')\n",
    "plt.title('Comparison of data validated and not validated by humans')\n",
    "plt.ylabel('Number of examples')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa en el cuadro y gráfico de los outputs de las dos celdas anteriores, que los datos validados por humanos pertenecen principalmente a las categorias 'NOTEBOOKS' y 'TABLETS', siendo que de los 5812 datos validados por humanos, 5512 (que corresponde aproximadamente al 88 %) pertenecen a alguna de esas dos categorias.\n",
    "\n",
    "La otra característica que se observa es que, aunque para todas las categorias el número de ejemplos no validados por humanos supera al de ejemplos validados por humanos, en las categorias 'NOTEBOOKS' y 'TABLETS', el número de ejemplos validados y no validados es del mismo orden de magnitud,  mientras que para las categorias 'CELLPHONES' y 'TELEPHONES', casi el 100 % de los datos son datos no validados por humanos; de hecho, apenas 41 de los 14037 ejemplos de 'TELEPHONES' son datos validados.\n",
    "\n",
    "Teniendo en cuenta estos dos critérios, y el hecho que un modelo simple es capaz de predecir correctamente una catidad estadísticamente significativa de datos en las categorias 'NOTEBOOKS' y 'TABLETS', se deduce que el tener una gran cantidad de datos no validados por usuários en el conjunto de trainning no es demasiado relevante desde que haya una cantidad similar de datos validados, pero puede ser sufuciente para impedir el aprendizado del modelo si estos datos están presentes en cantidades demasiado importantes con relación a los datos validados por usuários para una categoria específica.\n",
    "\n",
    "Teniendo esto en cuenta, a continuación se muestran resultados para un modelo entrenado utilizando conjuntos diferentes de datos y validado también en diferentes conjuntos de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSVM - para un conjunto reducido de datos (evaluación del efecto de la cantidad de datos por categoria, y de la importancia de la validación por humanos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación del nuevo conjunto de datos\n",
    "\n",
    "Este nuevo conjunto de entrenamiento es un conjunto reducido que contiene solamente los datos del conjunto de training original que son validados por humanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLETS       1000\n",
      "NOTEBOOKS     1000\n",
      "CELLPHONES     659\n",
      "TELEPHONES      41\n",
      "Name: Label, dtype: int64\n",
      "YES    2700\n",
      "Name: Human_validated, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tel = def_train_set[(def_train_set['Label'] == \"TELEPHONES\") & (def_train_set['Human_validated'] == \"YES\")]\n",
    "cel = def_train_set[(def_train_set['Label'] == \"CELLPHONES\") & (def_train_set['Human_validated'] == \"YES\")]\n",
    "tab = def_train_set[(def_train_set['Label'] == \"TABLETS\") & (def_train_set['Human_validated'] == \"YES\")]\n",
    "nob = def_train_set[(def_train_set['Label'] == \"NOTEBOOKS\") & (def_train_set['Human_validated'] == \"YES\")]\n",
    "# tel = def_train_set[(def_train_set['Label'] == \"TELEPHONES\")].sample(frac=1).reset_index(drop=True)\n",
    "# cel = def_train_set[(def_train_set['Label'] == \"CELLPHONES\")].sample(frac=1).reset_index(drop=True)\n",
    "# tab = def_train_set[(def_train_set['Label'] == \"TABLETS\")].sample(frac=1).reset_index(drop=True)\n",
    "# nob = def_train_set[(def_train_set['Label'] == \"NOTEBOOKS\")].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "frames = [tel.head(1000), cel.head(1000), tab.head(1000), nob.head(1000)]\n",
    "\n",
    "red_set = pd.concat(frames)\n",
    "red_set = red_set.sample(frac=1).reset_index(drop=True)\n",
    "print(red_set['Label'].value_counts())\n",
    "print(red_set['Human_validated'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NEW TRAINING SET PREPARATION\n",
    "\n",
    "new_train_numpy = red_set['Text'].to_numpy()\n",
    "\n",
    "new_Train_text = remove_non_alphan(new_train_numpy, separator = ' ')\n",
    "#print(Train_text)\n",
    "new_train_x_vectors = vectorizer.transform(new_Train_text)\n",
    "\n",
    "\n",
    "## NEW LABELS OF THE TRAINING SET\n",
    "\n",
    "new_y_numpy = red_set['Label'].to_numpy()\n",
    "#print(new_y_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelo con nuevo conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Model2 = clf_Lsvm.fit(new_train_x_vectors, new_y_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probando la predicción de los modelos en un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CELLPHONES'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = vectorizer.transform(['Motorola Moto G5 Plus Con Funda Y Vidrio De Regalo! Nuevos!'])\n",
    "Model2.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunas métricas del modelo LSVM entrenado sólo con datos validados por humanos:\n",
    "\n",
    "Notese que la validación a seguir es hecha sobre el conjunto original de validación del  archivo Validation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9847389558232932\n",
      "[0.9825784  0.9862543  0.98334966 1.        ]\n",
      "[[141   0   0   0]\n",
      " [  2 574   7   0]\n",
      " [  3   7 502   0]\n",
      " [  0   0   0   9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "\n",
    "\n",
    "print(Model2.score(val_x_vectors, val_label_numpy))\n",
    "print(f1_score(val_label_numpy, Model2.predict(val_x_vectors), average=None, labels=['CELLPHONES', 'NOTEBOOKS', 'TABLETS', 'TELEPHONES']))\n",
    "print(confusion_matrix(val_label_numpy, Model2.predict(val_x_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas arriba corresponden a las de un modelo entrenado con un conjunto de datos de diferente tamaño para cada categoria, pero todos siendo validados por humanos. En este caso, se observa que cuando las métricas del modelo son calculadas encima de un conjunto en el que todos los datos son también validados por humanos, como es el caso del conjunto de validación dado, el modelo se comporta bastante bien para todas las categorias. Obsérvese que en este caso el entrenamiento fue hecho con cantidades muy diferentes de datos en cada categoria, siendo 1000 para 'TABLETS' y 'NOTEBOOKS', pero apenas 41 para 'TELEPHONES'. Esta diferencia en la cantidad de datos no parece ser un problema pues métricas similares son obtenidas si el modelo se entrena con 41 datos para cada categoria (no mostrado).\n",
    "\n",
    "\n",
    "Como comentado anteriormente, el conjunto de validación dado no presenta una cantidad estadísticamente significativa de datos en la categoria 'TELEPHONES' por lo que este puede no ser aplicable en general. Por eso, a continuación se presentan estas mismas métricas calculadas encima de un conjunto mas general de datos, de aproximadamente el mismo tamaño que el conjunto de validación inicial (1200 elementos) pero en el que la cantidad de datos para cada categoria es el mismo y presenta además datos validados y no validados por humanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas calculadas para un conjunto de validación heterogéneo en términos de validación por humanos\n",
    "\n",
    "Los datos a seguir deben ser tomados del mismo training set ya que no hay mas datos disponibles, pero eso, aunque no es lo ideal, no es necesáriamente un problema ya que no todos los datos del conjunto fueron usandos para entrenar el Modelo2, así que no hay una intersección importante entre los conjuntos de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tel = def_train_set[(def_train_set['Label'] == \"TELEPHONES\")].sample(frac=1).reset_index(drop=True)\n",
    "n_cel = def_train_set[(def_train_set['Label'] == \"CELLPHONES\")].sample(frac=1).reset_index(drop=True)\n",
    "n_tab = def_train_set[(def_train_set['Label'] == \"TABLETS\")].sample(frac=1).reset_index(drop=True)\n",
    "n_nob = def_train_set[(def_train_set['Label'] == \"NOTEBOOKS\")].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "n_frames = [n_tel.head(300), n_cel.head(300), n_tab.head(300), n_nob.head(300)]\n",
    "\n",
    "n_set = pd.concat(n_frames)\n",
    "n_set = n_set.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n_set.head()\n",
    "n_train_numpy = n_set['Text'].to_numpy()\n",
    "n_Train_text = remove_non_alphan(n_train_numpy, separator = ' ')\n",
    "n_train_x_vectors = vectorizer.transform(n_Train_text)\n",
    "\n",
    "n_y_train = n_set['Label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525\n",
      "[0.12151067 0.91331269 0.95469256 0.0113852 ]\n",
      "[[ 37  31   8 224]\n",
      " [  0 295   5   0]\n",
      " [  1   4 295   0]\n",
      " [271  16  10   3]]\n"
     ]
    }
   ],
   "source": [
    "print(Model2.score(n_train_x_vectors, n_y_train))\n",
    "print(f1_score(n_y_train, Model2.predict(n_train_x_vectors,), average=None, labels=['CELLPHONES', 'NOTEBOOKS', 'TABLETS', 'TELEPHONES']))\n",
    "print(confusion_matrix(n_y_train, Model2.predict(n_train_x_vectors,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas arriba corresponden a las del modelo 2 validado en un conjunto que contiene datos validados y no validados por humanos y se observa que esta vez el modelo falla al predecir elementos de las categorias 'CELLPHONES' y 'TELEPHONES'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalización del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebas adicionales fueron hechas entrenando el modelo con el mismo número de datos en cada categoria (1000 para cada una), pero con una mezcla de datos validados y no validados por usuários, en ese caso las métricas no son aceptables cuando la validación es hecha sobre el conjunto de validación original (donde todos los datos son validados), pero mejoran al punto del factor F1 ser 0.93, 0.99, 0.98, 0.91 para 'CELLPHONES', 'NOTEBOOKS', 'TABLETS', y 'TELEPHONES', respectivamente, cuando validados sobre este último conjunto heterogéneo de datos en términos de validación por humanos (ver output de las 2 celdas abajo). Estos resultados se consideran válidos pues apenas 4000 de los 38705 datos fueron usados para entrenar el modelo, y tanto en el entrenamiento cuanto en la validación los datos fueron escogidos aleatoriamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TELEPHONES    1000\n",
      "TABLETS       1000\n",
      "CELLPHONES    1000\n",
      "NOTEBOOKS     1000\n",
      "Name: Label, dtype: int64\n",
      "NO     3134\n",
      "YES     866\n",
      "Name: Human_validated, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## DATA TO BE USED AS TRAINING SET FOR TESTING OTHER MODELS\n",
    "\n",
    "tel2 = def_train_set[(def_train_set['Label'] == \"TELEPHONES\")].sample(frac=1).reset_index(drop=True)\n",
    "cel2 = def_train_set[(def_train_set['Label'] == \"CELLPHONES\")].sample(frac=1).reset_index(drop=True)\n",
    "tab2 = def_train_set[(def_train_set['Label'] == \"TABLETS\")].sample(frac=1).reset_index(drop=True)\n",
    "nob2 = def_train_set[(def_train_set['Label'] == \"NOTEBOOKS\")].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "frames2 = [tel2.head(1000), cel2.head(1000), tab2.head(1000), nob2.head(1000)]\n",
    "\n",
    "red_set2 = pd.concat(frames2)\n",
    "red_set2 = red_set2.sample(frac=1).reset_index(drop=True)\n",
    "print(red_set2['Label'].value_counts())\n",
    "print(red_set2['Human_validated'].value_counts())\n",
    "\n",
    "\n",
    "## New training set preparation\n",
    "\n",
    "new_train_numpy2 = red_set2['Text'].to_numpy()\n",
    "\n",
    "new_Train_text2 = remove_non_alphan(new_train_numpy2, separator = ' ')\n",
    "\n",
    "new_train_x_vectors2 = vectorizer.transform(new_Train_text2)\n",
    "\n",
    "\n",
    "## New labels of the training set\n",
    "\n",
    "new_y_numpy2 = red_set2['Label'].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9433333333333334\n",
      "0.9245908495869539\n",
      "[0.91428571 0.98487395 0.97306397 0.9025974 ]\n",
      "[[272   0   2  26]\n",
      " [  0 293   3   4]\n",
      " [  1   2 289   8]\n",
      " [ 22   0   0 278]]\n"
     ]
    }
   ],
   "source": [
    "LSVM_MODEL = clf_Lsvm.fit(new_train_x_vectors2, new_y_numpy2)\n",
    "\n",
    "print(LSVM_MODEL.score(n_train_x_vectors, n_y_train))\n",
    "print(matthews_corrcoef(n_y_train, LSVM_MODEL.predict(n_train_x_vectors)))\n",
    "print(f1_score(n_y_train, LSVM_MODEL.predict(n_train_x_vectors,), average=None, labels=['CELLPHONES', 'NOTEBOOKS', 'TABLETS', 'TELEPHONES']))\n",
    "print(confusion_matrix(n_y_train, LSVM_MODEL.predict(n_train_x_vectors,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión sobre los datos\n",
    "\n",
    "Así, se concluye que para este conjunto de datos, un modelo simple como el LinearSVM es capaz de hacer una predicción relativamente confiable de las categorias (alrededor de 95 % de certeza en media) cuando **entrenado y probado solamente en datos validados por humanos**, y eso es verdad sin importar si el tamaño del conjunto de datos tomado para cada categoria es igual o no (aunque un conjunto mayor de  datos validados por humanos en la categoria 'TELEPHONES' es necesário para tener un resultado estadísticamente significativo). Sin embargo, en ese caso la generalización del modelo no es posible para conjuntos de datos con elementos no validados por humanos. Al mismo tiempo, si el modelo es entrenado con datos validados y no validados por humanos, este será capaz de hacer previsiones también con mas o menos 95 % de certeza en conjuntos de datos igualmente heterogéneos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando otros modelos\n",
    "\n",
    "Con el análisis anterior, ahora es posible concentrarse en la búsqueda y/o refinamiento de un modelo, conociendo las limitaciones del conjunto de datos dado. Para probar la conclusión de que un modelo de clasificación simple servirá relativamente bien cuando entrenado y validado en conjuntos heterogéneos de datos en términos de validación humana, se mostrarán a continuación los resultados para los algortimos de Desicion Trees y K-nearest-neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "## TRAINING THE MODEL\n",
    "\n",
    "DEC_MODEL = clf_dec.fit(new_train_x_vectors2, new_y_numpy2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probando la predicción del modelo con un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TELEPHONES'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = vectorizer.transform(['Motorola Moto G5 Plus Con Funda Y Vidrio De Regalo! Nuevos!'])\n",
    "DEC_MODEL.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas del modelo Desicion Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9366666666666666\n",
      "0.9159839630551285\n",
      "[0.90443686 0.97979798 0.97133221 0.89314195]\n",
      "[[265   0   2  33]\n",
      " [  0 291   3   6]\n",
      " [  2   2 288   8]\n",
      " [ 19   1   0 280]]\n"
     ]
    }
   ],
   "source": [
    "print(DEC_MODEL.score(n_train_x_vectors, n_y_train))\n",
    "print(matthews_corrcoef(n_y_train, DEC_MODEL.predict(n_train_x_vectors)))\n",
    "print(f1_score(n_y_train, DEC_MODEL.predict(n_train_x_vectors,), average=None, labels=['CELLPHONES', 'NOTEBOOKS', 'TABLETS', 'TELEPHONES']))\n",
    "print(confusion_matrix(n_y_train, DEC_MODEL.predict(n_train_x_vectors,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 4\n",
    "\n",
    "## TRAINING THE MODEL\n",
    "\n",
    "NEIGH = KNeighborsClassifier(n_neighbors = k).fit(new_train_x_vectors2, new_y_numpy2)\n",
    "\n",
    "NEIGH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas del modelo K-Neares_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9275\n",
      "0.9034036007905689\n",
      "[0.91       0.96283784 0.93442623 0.90301003]\n",
      "[[273   0   7  20]\n",
      " [  5 285   5   5]\n",
      " [  6   6 285   3]\n",
      " [ 16   1  13 270]]\n"
     ]
    }
   ],
   "source": [
    "print(NEIGH.score(n_train_x_vectors, n_y_train))\n",
    "print(matthews_corrcoef(n_y_train, NEIGH.predict(n_train_x_vectors)))\n",
    "print(f1_score(n_y_train, NEIGH.predict(n_train_x_vectors,), average=None, labels=['CELLPHONES', 'NOTEBOOKS', 'TABLETS', 'TELEPHONES']))\n",
    "print(confusion_matrix(n_y_train, NEIGH.predict(n_train_x_vectors,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión sobre los modelos\n",
    "\n",
    "Entre los modelos probados, el modelo que mejor predice la categoria a la cual un producto pertenece, basado en su título, es el modelo Linear Suport Vector Machine. En todos los casos, la mejor predicción es hecha para la categoria 'NOTEBOOKS' la cual es la categoria con más datos validados por humanos. \n",
    "\n",
    "Los resultados mostrados indican que los datos validados por usuários contienen textos más explicativos que facilitan el trabajo de los modelos de Aprendizado de Máquina, sin embargo, no resulta práctico entrenar los modelos sólo con estos datos \"de mejor calidad\" si se pretende usar el modelo para hacer predicciones en conjuntos  que contengan una gran proporción de datos no validados por usuários. Para esos casos el mejor conjunto de entrenameinto debe contener datos de ambos tipos, validados y no validados por humanos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando los modelos\n",
    "\n",
    "Se guardarán los tres modelos simples de predicción entrenados y validados en los mismo conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./LinearSVM.pkl', 'wb') as f: \n",
    "    pickle.dump(LSVM_MODEL, f)\n",
    "    \n",
    "with open('./DecTree.pkl', 'wb') as f: \n",
    "    pickle.dump(DEC_MODEL, f)\n",
    "    \n",
    "with open('./K_neigh.pkl', 'wb') as f: \n",
    "    pickle.dump(NEIGH, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como cargar y usar los modelos\n",
    "\n",
    "Estos modelos pueden ser cargados para ser usados posteriormente así:\n",
    "\n",
    "\n",
    "with open('./model_name.pkl', 'rb') as f:\n",
    "\n",
    "    loaded_model = pickle.load(f) \n",
    "    \n",
    "    \n",
    "y necesitan como datos de entrada matrices tipo sparce de datos de texto procesados con CountVectorizer para las variables independientes, y vectores de formato numpy para los 'labels'. \n",
    "\n",
    "Dentro de este archivo, los inputs y labels en ese formato pueden ser obtenidos procesando los datos provenientes de un dataframe (df) así:\n",
    "\n",
    "df_to_numpy = df['col_text'].to_numpy()\n",
    "data_clean = remove_non_alphan(new_train_numpy2, separator = ' ')\n",
    "\n",
    "\n",
    "input_x = vectorizer.transform(data_clean)\n",
    "label = df['col_label'].to_numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test adicionales\n",
    "\n",
    "Las celdas abajo contienen algunas ideas para refinamiento de modelo y/o testes de hipótesis, pero no hacen parte de la tarea propuesta y pueden ser descartadas de la evaluación de la misma. \n",
    "\n",
    "Estas son pruebas muy preliminares usando otras formas de vectorización de los textos, y de un modelo de red neuronal que contiene una 'layer' embedding, pero en la que no fue hecho ningún intento sério de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors en modelo LinearSVM\n",
    "\n",
    "Este es un test para ver si una aproximación diferente de la vectorización de los textos mejora el desempeño del modelo. Esta vectorización busca cierta conexión semántica entre las palabras con una pipeline pre-entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [nlp(text) for text in new_Train_text2]\n",
    "new_train_x_word_vectors = [x.vector for x in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_Lsvm_wv = LinearSVC()\n",
    "clf_Lsvm_wv.fit(new_train_x_word_vectors, new_y_numpy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TELEPHONES'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = ['Motorola Moto G5 Plus Con Funda Y Vidrio De Regalo! Nuevos!'] \n",
    "test_docs = [nlp(text) for text in test_x]\n",
    "test_x_word_vectors =  [x.vector for x in test_docs]\n",
    "\n",
    "clf_Lsvm_wv.predict(test_x_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360000\n",
      "1200\n",
      "[0.87296417 0.98163606 0.95798319 0.88175676]\n"
     ]
    }
   ],
   "source": [
    "docs_val = [nlp(text) for text in n_Train_text]\n",
    "test_x_word_vectors = [x.vector for x in docs_val]\n",
    "print (np.size(test_x_word_vectors))\n",
    "print(np.size(n_y_train))\n",
    "print(f1_score(n_y_train, clf_Lsvm_wv.predict(test_x_word_vectors), average=None, labels=['CELLPHONES', 'NOTEBOOKS', 'TABLETS', 'TELEPHONES']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente la hipótesis inicial de que esta aproximación para la vectorización de los textos no resultaria más adecuada para el caso específico de estos titulos de productos estaba correcta pues este modelo tiene métricas un poco peores que las obtenidas con un simple bag of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None, \n",
    "                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                      lower=True,\n",
    "                      split=' ',\n",
    "                      char_level=False,\n",
    "                      oov_token='<UNK>',\n",
    "                      document_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(new_Train_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['num_words', 'filters', 'lower', 'split', 'char_level', 'oov_token', 'document_count', 'word_counts', 'word_docs', 'index_docs', 'index_word', 'word_index'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_config = tokenizer.get_config()\n",
    "tokenizer_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[22, 34, 133, 65, 196, 15, 159, 13, 139, 46, 455],\n",
       " [1795, 1187, 6, 899, 560, 1796, 642, 38, 213, 87, 1797],\n",
       " [14, 423, 19, 376, 40, 70, 1798],\n",
       " [495, 54, 87, 42, 186, 1799, 109, 6, 62, 214],\n",
       " [643, 1800, 27, 72]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts_seq = tokenizer.texts_to_sequences(new_Train_text2)\n",
    "val_texts_seq = tokenizer.texts_to_sequences(n_Train_text)\n",
    "print(type(train_texts_seq))\n",
    "train_texts_seq[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(train_texts_seq, maxlen=15, padding='post', truncating='post')\n",
    "padded_x_val = tf.keras.preprocessing.sequence.pad_sequences(val_texts_seq, maxlen=15, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 15)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 15)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>Human_validated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>iPad Pro 12.9 Generación 2 256 Gb Teclado Fund...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Omilik 6v - 6.5v Ac / Dc Adaptador Para Siemen...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>iPhone 5s 16gb. Originales En Caja Termosellada</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tel Inalámbrico Gigaset Nuevo Modelo As405 Dec...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Notebooks Liquidacion Intel-i3</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                               Text Human_validated\n",
       "0      2  iPad Pro 12.9 Generación 2 256 Gb Teclado Fund...              NO\n",
       "1      0  Omilik 6v - 6.5v Ac / Dc Adaptador Para Siemen...              NO\n",
       "2      3    iPhone 5s 16gb. Originales En Caja Termosellada              NO\n",
       "3      0  Tel Inalámbrico Gigaset Nuevo Modelo As405 Dec...              NO\n",
       "4      1                     Notebooks Liquidacion Intel-i3             YES"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup_nums = {\"Label\":{\"CELLPHONES\": 0, \"NOTEBOOKS\": 1, \"TABLETS\": 2, \"TELEPHONES\":3}}\n",
    "\n",
    "#obj_df_train = def_train_set.replace(cleanup_nums)\n",
    "obj_df_train = red_set2.replace(cleanup_nums)\n",
    "\n",
    "obj_df_val = n_set.replace(cleanup_nums)\n",
    "obj_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3, 0, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_numpy = obj_df_train['Label'].to_numpy()\n",
    "y_val_numpy = obj_df_val['Label'].to_numpy()\n",
    "y_train_numpy[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          320000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 322,180\n",
      "Trainable params: 322,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.8125 - accuracy: 0.2542 - mae: 1.3750 - val_loss: 2.8734 - val_accuracy: 0.3187 - val_mae: 1.3945\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.8125 - accuracy: 0.2605 - mae: 1.3750 - val_loss: 2.8734 - val_accuracy: 0.3063 - val_mae: 1.3945\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 2.8125 - accuracy: 0.2598 - mae: 1.3750 - val_loss: 2.8734 - val_accuracy: 0.2812 - val_mae: 1.3945\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 2.8125 - accuracy: 0.2463 - mae: 1.3750 - val_loss: 2.8734 - val_accuracy: 0.2344 - val_mae: 1.3945\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 2.8125 - accuracy: 0.2475 - mae: 1.3750 - val_loss: 2.8734 - val_accuracy: 0.3094 - val_mae: 1.3945\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 2.8125 - accuracy: 0.2530 - mae: 1.3750 - val_loss: 2.8734 - val_accuracy: 0.2734 - val_mae: 1.3945\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 2.8125 - accuracy: 0.2612 - mae: 1.3750 - val_loss: 2.8734 - val_accuracy: 0.2750 - val_mae: 1.3945\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 2.8125 - accuracy: 0.2390 - mae: 1.3750 - val_loss: 2.8734 - val_accuracy: 0.2922 - val_mae: 1.3945\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 2.8125 - accuracy: 0.2510 - mae: 1.3750 - val_loss: 2.8734 - val_accuracy: 0.2594 - val_mae: 1.3945\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 2.8125 - accuracy: 0.2475 - mae: 1.3750 - val_loss: 2.8734 - val_accuracy: 0.2703 - val_mae: 1.3945\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Embedding(input_dim=20000, output_dim=16, mask_zero=False),\n",
    "                              tf.keras.layers.LSTM(units=16),\n",
    "                             tf.keras.layers.Dense(units=4, activation='softmax')])\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam', metrics=['accuracy', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(padded_x_train, y_train_numpy, epochs=10, batch_size=32, validation_data=(padded_x_val, y_val_numpy), validation_steps=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24998035, 0.2500074 , 0.24994726, 0.25006497]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_x_val[None, 0 ,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
